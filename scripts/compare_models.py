# compare_models.py - æ¯”è¼ƒå¤šå€‹æ¨¡å‹åœ¨åŒä¸€ç’°å¢ƒä¸‹çš„è¡¨ç¾

import os
import sys
import yaml
import torch
import numpy as np
import matplotlib.pyplot as plt

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from envs.baby_pong_env import BabyPongBounceEnv as BabyPongEnv
from models.qnet import QNet

# -------------------------
# è¼‰å…¥è¨­å®šæª”
# -------------------------
with open("config.yaml", "r") as f:
    cfg = yaml.safe_load(f)

# -------------------------
# è¨­å®šè¦æ¯”è¼ƒçš„æ¨¡å‹æª”æ¡ˆæ¸…å–®
# -------------------------
model_files = [
    "checkpoints/model_traget2_ep399.pth",
    "checkpoints/model_traget2_ep799.pth",
    "checkpoints/model_traget2_ep1199.pth",
    "checkpoints/model_traget2_ep1599.pth",
    "checkpoints/model_traget2_ep1999.pth"
]

# -------------------------
# æ¸¬è©¦æ¯å€‹æ¨¡å‹è¡¨ç¾
# -------------------------
def evaluate_model(path, episodes=10):
    env = BabyPongEnv(**cfg['env'])
    state_dim = env.observation_space.shape[0]
    action_dim = env.action_space.n
    model = QNet(state_dim, action_dim)
    checkpoint = torch.load(path)
    model.load_state_dict(checkpoint['model'])
    model.eval()

    total_rewards = []

    for _ in range(episodes):
        state, _ = env.reset()
        done = False
        total_reward = 0
        while not done:
            with torch.no_grad():
                action = model(torch.tensor(state, dtype=torch.float32)).argmax().item()
            state, reward, done, _, _ = env.step(action)
            total_reward += reward
        total_rewards.append(total_reward)

    env.close()
    return np.mean(total_rewards), np.std(total_rewards)

# -------------------------
# ä¸»ç¨‹å¼ï¼šæ¯”è¼ƒçµæœ + ç¹ªåœ–
# -------------------------
labels = []
avgs = []
stds = []

print("ğŸ“Š Model comparison results:")
for path in model_files:
    if not os.path.exists(path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹ï¼š{path}")
        continue
    name = os.path.basename(path)
    avg, std = evaluate_model(path, episodes=10)
    print(f"{name}: Avg = {avg:.2f}, Std = {std:.2f}")
    labels.append(name)
    avgs.append(avg)
    stds.append(std)

# ç•«åœ–æ¯”è¼ƒ
plt.figure(figsize=(10, 6))
plt.barh(labels, avgs, xerr=stds, color="skyblue")
plt.xlabel("Average Reward")
plt.title("Model performance comparison (Â± std)")
plt.tight_layout()
plt.grid(True, axis='x')
plt.show()
